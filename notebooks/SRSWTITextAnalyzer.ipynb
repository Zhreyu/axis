{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# SRSWTITextAnalyzer\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhreyas/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-10 14:36:21.501176: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741597581.521085  893328 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741597581.526598  893328 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 14:36:21.547328: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:datasets:PyTorch version 2.5.0 available.\n",
      "INFO:datasets:TensorFlow version 2.18.0 available.\n",
      "INFO:datasets:JAX version 0.5.2 available.\n",
      "INFO:SRSWTI:SRSWTI Text Analysis Engine initialized successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------  Imports -------------------------------\n",
    "from srswti_axis import SRSWTITextAnalyzer\n",
    "from utils import call_groq_llm, SAMPLE_DOCS\n",
    "# import nltk\n",
    "# nltk.download('averaged_perceptron_tagger_eng')\n",
    "# nltk.download('maxent_ne_chunker_tab')\n",
    "# nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------- Basic  Demos -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SRSWTI:Initializing SRSWTI Text Analyzer\n",
      "INFO:SRSWTI:SRSWTI Text Analyzer initialized with standard grammar patterns\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SRSWTI text analyzer\n",
    "core_analyzer = SRSWTITextAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SRSWTI:Starting SRSWTI text analysis\n",
      "INFO:SRSWTI:Completed analysis of 2 sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Core Analysis Example 1 ==\n",
      "{'summary': {'text_length': 134, 'sentence_count': 2, 'overall_sentiment': {'compound': 0.57375, 'pos': 0.37, 'neg': 0.0, 'neu': 0.63}, 'entity_count': 2, 'unique_entities': 2}, 'sentiment': {'overall': {'compound': 0.57375, 'pos': 0.37, 'neg': 0.0, 'neu': 0.63}, 'by_sentence': [{'text': '\\nApple Inc. reported strong quarterly results.', 'scores': {'neg': 0.0, 'neu': 0.602, 'pos': 0.398, 'compound': 0.5106}}, {'text': \"The company's innovation soared, but new regulatory hurdles might slow future growth.\", 'scores': {'neg': 0.0, 'neu': 0.658, 'pos': 0.342, 'compound': 0.6369}}]}, 'entities': [{'text': 'Apple', 'label': 'PERSON', 'confidence': 0.85, 'position': {'start': 0, 'end': 0}}, {'text': 'Inc.', 'label': 'ORGANIZATION', 'confidence': 0.85, 'position': {'start': 0, 'end': 0}}], 'structure': {'phrases': {'noun_phrases': ['strong quarterly results', 'The company', 'innovation', 'new regulatory hurdles', 'future growth'], 'verb_phrases': ['reported strong quarterly results', 'slow future growth'], 'prep_phrases': []}, 'by_sentence': [{'text': '\\nApple Inc. reported strong quarterly results.', 'structure': {'noun_phrases': ['strong quarterly results'], 'verb_phrases': ['reported strong quarterly results'], 'prep_phrases': [], 'adj_phrases': []}}, {'text': \"The company's innovation soared, but new regulatory hurdles might slow future growth.\", 'structure': {'noun_phrases': ['The company', 'innovation', 'new regulatory hurdles', 'future growth'], 'verb_phrases': ['slow future growth'], 'prep_phrases': [], 'adj_phrases': []}}]}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Basic structure + sentiment\n",
    "text_core_1 = \"\"\"\n",
    "Apple Inc. reported strong quarterly results. \n",
    "The company's innovation soared, but new regulatory hurdles might slow future growth.\n",
    "\"\"\"\n",
    "analysis_1 = core_analyzer.analyze_text(text_core_1)\n",
    "print(\"== Core Analysis Example 1 ==\")\n",
    "print(analysis_1, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SRSWTI:Starting SRSWTI text analysis\n",
      "INFO:SRSWTI:Completed analysis of 1 sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Core Analysis Example 2, Named Entities ==\n",
      "[{'text': 'QuantumCorp', 'label': 'GPE', 'confidence': 0.85, 'position': {'start': 0, 'end': 0}}, {'text': 'Germany', 'label': 'GPE', 'confidence': 0.85, 'position': {'start': 0, 'end': 0}}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) Named Entity Recognition & chunk-level sentiment\n",
    "text_core_2 = \"\"\"\n",
    "QuantumCorp, a startup from Germany, secured $500 million in funding \n",
    "to develop a 5000-qubit quantum computer by 2026. \n",
    "\"\"\"\n",
    "analysis_2 = core_analyzer.analyze_text(text_core_2)\n",
    "print(\"== Core Analysis Example 2, Named Entities ==\")\n",
    "print(analysis_2.get(\"entities\", []), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SRSWTI:Starting SRSWTI text analysis\n",
      "INFO:SRSWTI:Completed analysis of 1 sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Core Analysis Example 2, Named Entities ==\n",
      "[{'text': 'QuantumCorp', 'label': 'GPE', 'confidence': 0.85, 'position': {'start': 0, 'end': 0}}, {'text': 'Germany', 'label': 'GPE', 'confidence': 0.85, 'position': {'start': 0, 'end': 0}}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Named Entity Recognition & chunk-level sentiment\n",
    "text_core_2 = \"\"\"\n",
    "QuantumCorp, a startup from Germany, secured $500 million in funding \n",
    "to develop a 5000-qubit quantum computer by 2026. \n",
    "\"\"\"\n",
    "analysis_2 = core_analyzer.analyze_text(text_core_2)\n",
    "print(\"== Core Analysis Example 2, Named Entities ==\")\n",
    "print(analysis_2.get(\"entities\", []), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SRSWTI:Starting SRSWTI text analysis\n",
      "INFO:SRSWTI:Completed analysis of 1 sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Core Analysis Example 3, structure for LLM prompt ==\n",
      "{'phrases': {'noun_phrases': ['a surprising turn', 'events', 'personal reasons', 'health', 'concerns'], 'verb_phrases': ['citing personal reasons'], 'prep_phrases': ['In a surprising turn', 'of events']}, 'by_sentence': [{'text': '\\nIn a surprising turn of events, the CFO resigned abruptly, \\nciting personal reasons and health concerns.', 'structure': {'noun_phrases': ['a surprising turn', 'events', 'personal reasons', 'health', 'concerns'], 'verb_phrases': ['citing personal reasons'], 'prep_phrases': ['In a surprising turn', 'of events'], 'adj_phrases': []}}]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) Using the structural breakdown to feed an LLM prompt\n",
    "text_core_3 = \"\"\"\n",
    "In a surprising turn of events, the CFO resigned abruptly, \n",
    "citing personal reasons and health concerns.\n",
    "\"\"\"\n",
    "analysis_3 = core_analyzer.analyze_text(text_core_3)\n",
    "print(\"== Core Analysis Example 3, structure for LLM prompt ==\")\n",
    "print(analysis_3.get(\"structure\", {}), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------- RAG Demos ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_demo_a(doc):\n",
    "    \"\"\"\n",
    "    Analyze a doc's structure & entities, feed to Groq LLM.\n",
    "    \"\"\"\n",
    "    analysis = core_analyzer.analyze_text(doc)\n",
    "    prompt = (\n",
    "        f\"Analyzed doc:\\n{doc}\\n\\n\"\n",
    "        f\"Entities: {analysis.get('entities', [])}\\n\"\n",
    "        f\"Structure: {analysis.get('structure', {})}\\n\"\n",
    "        \"Please provide a short summary or insight.\"\n",
    "    )\n",
    "    llm_response = call_groq_llm(prompt)\n",
    "    print(\"[Theorem2 RAG Demo A] LLM Response:\\n\", llm_response, \"\\n\")\n",
    "\n",
    "def rag_demo_b(user_query, docs=SAMPLE_DOCS):\n",
    "    \"\"\"\n",
    "    1) Analyze each doc\n",
    "    2) 'Retrieve' docs that mention certain keywords\n",
    "    3) Summarize with Groq\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        print(\"[Theorem2 RAG Demo B] No docs.\")\n",
    "        return\n",
    "\n",
    "    retrieved = []\n",
    "    for d in docs:\n",
    "        if \"Neural\" in d or \"Reinforcement\" in d:\n",
    "            analysis = core_analyzer.analyze_text(d)\n",
    "            retrieved.append((d, analysis.get(\"entities\", None)))\n",
    "\n",
    "    prompt = (\n",
    "        f\"User Query: {user_query}\\n\\n\"\n",
    "        f\"Retrieved docs: {retrieved}\\n\"\n",
    "        \"Create a combined answer or summary.\"\n",
    "    )\n",
    "    llm_response = call_groq_llm(prompt)\n",
    "    print(\"[Theorem2 RAG Demo B] LLM Response:\\n\", llm_response, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SRSWTI:Starting SRSWTI text analysis\n",
      "INFO:SRSWTI:Completed analysis of 10 sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem2 RAG Demo A] LLM Response:\n",
      " [Groq LLM] The analyzed document provides an overview of neural networks, a fundamental concept in artificial intelligence. Neural networks are computational models inspired by the human brain's architecture, consisting of interconnected nodes (neurons) organized in layers. They can learn and adapt through training processes, making them a crucial tool for various applications such as image and speech recognition, natural language processing, and medical diagnosis. Despite challenges like overfitting and interpretability, neural networks continue to drive innovations in numerous fields. The document highlights key concepts, types, and applications of neural networks, providing a comprehensive introduction to this complex topic. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if SAMPLE_DOCS:\n",
    "    doc_for_demo2 = SAMPLE_DOCS[0]\n",
    "    rag_demo_a(doc_for_demo2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SRSWTI:Starting SRSWTI text analysis\n",
      "INFO:SRSWTI:Completed analysis of 10 sentences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem2 RAG Demo B] LLM Response:\n",
      " [Groq LLM] Neural networks are computational models inspired by the human brain's architecture, consisting of interconnected nodes (neurons) organized in layers: input, hidden, and output layers. The key concepts of neural networks include their structure, where neurons receive inputs, apply weights, sum them, and pass through activation functions, and learning, where networks learn by adjusting weights through training processes like backpropagation. Activation functions, such as ReLU, sigmoid, or tanh, determine neuron output.\n",
      "\n",
      "There are several types of neural networks, including feedforward neural networks, convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformers. Feedforward neural networks allow information to flow in one direction, while CNNs are specialized for image processing, RNNs handle sequential data with memory, and transformers are an advanced architecture for natural language processing.\n",
      "\n",
      "Neural networks have a wide range of applications, including image and speech recognition, natural language processing, game playing and decision making, and medical diagnosis and predictions. However, they also come with challenges, such as overfitting, computational intensity, and interpretability. Despite these challenges, neural networks remain at the forefront of artificial intelligence, driving innovations across numerous fields.\n",
      "\n",
      "In terms of specific topics like ReLU, CNNs, RNNs, and transformers, these are all important components or types of neural networks. ReLU is a commonly used activation function, while CNNs and RNNs are types of neural networks with specific strengths. Transformers are a more recent development, particularly suited for natural language processing tasks.\n",
      "\n",
      "Overall, neural networks are a powerful tool for artificial intelligence, with applications in many areas. While they can be complex and challenging to work with, they offer a wide range of possibilities for innovation and discovery. \n",
      "\n",
      "Note: The provided document does not contain information about Reinforcement Learning (RL). If you would like to know about RL, I can provide you with a separate summary. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_b(\"Tell me about neural networks or RL\", SAMPLE_DOCS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
