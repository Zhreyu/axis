{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###############################################################################\n",
    "# SRSWTIPureFlow\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhreyas/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-11 23:45:45.436053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741716945.448706 1034843 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741716945.452399 1034843 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-11 23:45:45.465462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:datasets:PyTorch version 2.5.0 available.\n",
      "INFO:datasets:TensorFlow version 2.18.0 available.\n",
      "INFO:datasets:JAX version 0.5.2 available.\n",
      "INFO:SRSWTI:SRSWTI Text Analysis Engine initialized successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ---------------------------  Imports -------------------------------\n",
    "from srswti_axis import SRSWTIPureFlow\n",
    "from utils import call_groq_llm, SAMPLE_DOCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------  Basic 3 Demos -------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the pure flow merger\n",
    "pure_flow_merger = SRSWTIPureFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Pure Flow 1 ==\n",
      "['COVID-19 vaccines prevent severe illness.', 'mRNA tech powers latest vaccine generation.'] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a list of documents about COVID vaccines\n",
    "pf_docs1 = [\n",
    "    \"COVID-19 vaccines prevent severe illness.\",\n",
    "    \"mRNA tech powers latest vaccine generation.\"\n",
    "]\n",
    "\n",
    "# Merge documents based on content similarity\n",
    "# This technique groups similar content together to create a coherent merged text\n",
    "sim_merged = pure_flow_merger.merge_by_similarity(pf_docs1)\n",
    "\n",
    "# Print the result with a header for clarity\n",
    "print(\"== Pure Flow 1 ==\")\n",
    "print(sim_merged, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Pure Flow 2 ==\n",
      "Climate change -> extreme weather. Rising sea levels threaten coasts. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a list of documents about climate change\n",
    "pf_docs2 = [\n",
    "    \"Climate change -> extreme weather.\",\n",
    "    \"Rising sea levels threaten coasts.\"\n",
    "]\n",
    "# Merge documents sequentially\n",
    "# This technique merges the documents in the order they are provided\n",
    "seq_merged = pure_flow_merger.merge_sequential(pf_docs2, max_chunk_size=100, overlap=True)\n",
    "print(\"== Pure Flow 2 ==\")\n",
    "print(seq_merged, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m981.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "== Pure Flow 3 ==\n",
      "{'Topic 0: volatility, stock, soared': 'Stock market volatility soared.\\n\\nInvestors fear global recession.', 'Topic 1: central, banks, adjusted': 'Central banks adjusted interest rates.'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pf_docs3 = [\n",
    "    \"Stock market volatility soared.\",\n",
    "    \"Central banks adjusted interest rates.\",\n",
    "    \"Investors fear global recession.\"\n",
    "]\n",
    "# Merge documents based on topic similarity\n",
    "# This technique groups documents based on their topic similarity\n",
    "topic_merged = pure_flow_merger.merge_by_topic(pf_docs3, num_topics=2)\n",
    "print(\"== Pure Flow 3 ==\")\n",
    "print(topic_merged, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------- RAG Demos ----------------------\n",
    "def rag_demo_a(docs=SAMPLE_DOCS):\n",
    "    '''\n",
    "    Demonstrates RAG (Retrieval-Augmented Generation) with similarity-based document merging.\n",
    "    \n",
    "    This function merges the provided documents based on content similarity,\n",
    "    creates a prompt with the merged text, and calls a Groq LLM to summarize\n",
    "    the main topics.\n",
    "    \n",
    "    Args:\n",
    "        docs (list): List of document strings to process. Defaults to SAMPLE_DOCS.\n",
    "    \n",
    "    Returns:\n",
    "        None: Prints the LLM response to the console.\n",
    "    '''\n",
    "    merged_text = pure_flow_merger.merge_by_similarity(docs)\n",
    "    prompt = f\"Similarity-based merged:\\n{merged_text}\\nSummarize the main topics.\"\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem5 RAG Demo A] LLM:\\n\", resp, \"\\n\")\n",
    "\n",
    "def rag_demo_b(docs=SAMPLE_DOCS):\n",
    "    '''\n",
    "    Demonstrates RAG (Retrieval-Augmented Generation) with topic-based document merging.\n",
    "    \n",
    "    This function merges the provided documents based on topic similarity,\n",
    "    creates a prompt with the merged text, and calls a Groq LLM to elaborate\n",
    "    on the identified topics.\n",
    "    \n",
    "    Args:\n",
    "        docs (list): List of document strings to process. Defaults to SAMPLE_DOCS.\n",
    "    \n",
    "    Returns:\n",
    "        None: Prints the LLM response to the console.\n",
    "    '''\n",
    "    merged_text = pure_flow_merger.merge_by_topic(docs, num_topics=2)\n",
    "    prompt = f\"Topic-based merged:\\n{merged_text}\\nElaborate on the topics.\"\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem5 RAG Demo B] LLM:\\n\", resp, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem5 RAG Demo A] LLM:\n",
      " [Groq LLM] The main topics discussed in the text are:\n",
      "\n",
      "1. **Generative AI and Blockchain Integration**: The intersection of artificial intelligence and blockchain technology, including applications such as NFT creation, decentralized AI training, and on-chain AI models.\n",
      "2. **Neural Networks**: An overview of neural networks, including their structure, learning processes, types (e.g., feedforward, convolutional, recurrent), and applications (e.g., image recognition, natural language processing).\n",
      "3. **Quantum Computing**: The principles and potential of quantum computing, including its potential to solve complex problems exponentially faster than classical computers, and its potential impact on fields such as cryptography, artificial intelligence, and materials science.\n",
      "\n",
      "These topics are all related to advanced technologies and their potential applications and challenges. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_a(SAMPLE_DOCS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem5 RAG Demo B] LLM:\n",
      " [Groq LLM] The provided text discusses two primary topics: artificial intelligence (AI) with a focus on neural networks and their integration with blockchain technology, and quantum computing, including its principles, potential impacts, and challenges, particularly in the context of cryptography.\n",
      "\n",
      "### Topic 0: AI, Neural Networks, and Blockchain Integration\n",
      "\n",
      "#### Overview of Neural Networks\n",
      "\n",
      "Neural networks are a foundational element of artificial intelligence, inspired by the structure and function of the human brain. These networks consist of layers of interconnected nodes (neurons) that process inputs through complex algorithms, allowing them to learn from data and make predictions or decisions. The key concepts in neural networks include their structure, the process of learning through adjusting weights and biases, and the role of activation functions in determining the output of each neuron.\n",
      "\n",
      "#### Types of Neural Networks\n",
      "\n",
      "There are several types of neural networks, each designed for specific tasks:\n",
      "- **Feedforward Neural Networks**: These are the simplest form, where information flows only in one direction, from input layer to output layer, with no feedback loops.\n",
      "- **Convolutional Neural Networks (CNNs)**: Specialized for image and video processing, CNNs use convolutional and pooling layers to extract features.\n",
      "- **Recurrent Neural Networks (RNNs)**: Designed to handle sequential data, RNNs have feedback connections, allowing them to keep track of a hidden state over time, which is useful for tasks like speech recognition or natural language processing.\n",
      "- **Transformers**: An advanced architecture primarily used in natural language processing, transformers rely entirely on self-attention mechanisms, allowing for more parallelization and thus being particularly useful for sequence-to-sequence tasks.\n",
      "\n",
      "#### Applications of Neural Networks\n",
      "\n",
      "Neural networks have a wide range of applications, including but not limited to:\n",
      "- Image and speech recognition\n",
      "- Natural language processing\n",
      "- Game playing and decision making\n",
      "- Medical diagnosis and predictions\n",
      "\n",
      "#### Challenges\n",
      "\n",
      "Despite their capabilities, neural networks face challenges such as overfitting (when a model becomes too specialized to the training data), computational intensity, and interpretability issues (understanding why a model made a particular decision).\n",
      "\n",
      "#### Integration with Blockchain\n",
      "\n",
      "The integration of neural networks with blockchain technology offers exciting possibilities:\n",
      "- **Generative AI and NFT Creation**: Unique digital assets created by generative AI can be minted as Non-Fungible Tokens (NFTs), with blockchain serving as a platform for verifying their authenticity and provenance.\n",
      "- **Decentralized AI Training**: Blockchain can facilitate the distributed training of AI models, with token incentives for those contributing computing resources or data.\n",
      "- **On-chain AI Models**: Deploying AI models directly on blockchain enables transparent and verifiable AI inference.\n",
      "- **Governance and Data Marketplaces**: Decentralized Autonomous Organizations (DAOs) can govern AI systems, and blockchain can host data marketplaces where data owners are fairly compensated for their data.\n",
      "\n",
      "### Topic 1: Quantum Computers and Cryptography\n",
      "\n",
      "#### Introduction to Quantum Computing\n",
      "\n",
      "Quantum computing is based on the principles of quantum mechanics, using quantum bits (qubits) that can exist in multiple states simultaneously, unlike classical bits which can only be 0 or 1. This property allows quantum computers to perform certain calculations much faster than classical computers, particularly in areas like factoring large numbers and simulating complex quantum systems.\n",
      "\n",
      "#### Potential Impact\n",
      "\n",
      "The potential impact of quantum computing is vast, affecting fields such as cryptography, drug discovery, materials science, and artificial intelligence. In cryptography, quantum computers could potentially break current encryption methods that rely on the difficulty of factoring large prime numbers, prompting the development of quantum-resistant (post-quantum) cryptography.\n",
      "\n",
      "#### Challenges in Quantum Computing\n",
      "\n",
      "Despite the potential, quantum computing faces significant challenges:\n",
      "- **Qubit Stability and Error Correction**: Maintaining the quantum state of qubits is difficult due to decoherence, and correcting errors in quantum computations is a complex task.\n",
      "- **Scaling Issues**: Currently, quantum computers are small-scale and need to be scaled up while maintaining control over the quantum states of the qubits.\n",
      "\n",
      "#### Quantum Computing and Cryptography\n",
      "\n",
      "The advent of quantum computing poses a significant threat to current cryptographic systems. Algorithms like Shor's algorithm can factor large numbers exponentially faster than the best known classical algorithms, which could break many encryption systems currently in use. This has led to the development of post-quantum cryptography, including lattice-based, hash-based, and code-based cryptographic protocols designed to be secure against both classical and quantum computers.\n",
      "\n",
      "In conclusion, both AI/neural networks and quantum computing are at the forefront of technological innovation, with the potential to revolutionize numerous fields. However, they also present significant challenges, from the interpretability and ethical use of AI to the practical realization and security implications of quantum computing. Addressing these challenges will be crucial for harnessing the full potential of these technologies. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_b(SAMPLE_DOCS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
