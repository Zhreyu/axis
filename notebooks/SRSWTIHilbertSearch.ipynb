{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# SRSWTIHilbertSearch\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhreyas/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-11 23:42:32.523950: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741716752.537289 1021057 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741716752.541078 1021057 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-11 23:42:32.555896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:datasets:PyTorch version 2.5.0 available.\n",
      "INFO:datasets:TensorFlow version 2.18.0 available.\n",
      "INFO:datasets:JAX version 0.5.2 available.\n",
      "INFO:SRSWTI:SRSWTI Text Analysis Engine initialized successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------  Imports ------------------------------\n",
    "from srswti_axis import SRSWTIHilbertSearch\n",
    "from utils import call_groq_llm, SAMPLE_DOCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------  Basic Demos ------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 25.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 22.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SRSWTIHilbertSearch with pointwise approach\n",
    "# (This compares individual documents against queries)\n",
    "hilbert = SRSWTIHilbertSearch(approach='pointwise')\n",
    "\n",
    "# Define training data:\n",
    "# 1. List of example queries across different domains\n",
    "train_queries = [\"machine learning\", \"sports\", \"finance\"]\n",
    "\n",
    "# 2. List of lists, where each sublist contains documents related to the corresponding query\n",
    "train_docs = [\n",
    "    [\"ML doc1\", \"ML doc2\", \"ML doc3\"],             # Documents for \"machine learning\"\n",
    "    [\"sports doc1\", \"sports doc2\", \"sports doc3\"],  # Documents for \"sports\"\n",
    "    [\"finance doc1\", \"finance doc2\", \"finance doc3\"] # Documents for \"finance\"\n",
    "]\n",
    "\n",
    "# 3. Relevance scores for each document-query pair\n",
    "# Higher scores indicate more relevant documents (1.0 is most relevant)\n",
    "train_relevances = [\n",
    "    [1.0, 0.8, 0.2],  # Relevance scores for ML documents\n",
    "    [0.9, 0.85, 0.3], # Relevance scores for sports documents\n",
    "    [1.0, 0.5, 0.4]   # Relevance scores for finance documents\n",
    "]\n",
    "\n",
    "# Train the model for 2 epochs using the training data\n",
    "hilbert.train(train_queries, train_docs, train_relevances, epochs=2)\n",
    "\n",
    "# Uncomment to save the trained model to disk\n",
    "# hilbert.save_model('hilbert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 22.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Hilbert 2: pointwise ==\n",
      "[(np.int64(0), np.float32(0.5130338)), (np.int64(1), np.float32(0.47368836)), (np.int64(2), np.float32(0.47124225))] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the trained model with new documents\n",
    "test_docs = [\"ML doc 4\", \"Some sports doc4\", \"Sport Doc 4\"]\n",
    "\n",
    "# Rank test documents for \"machine learning\" query using pointwise approach\n",
    "rank_results = hilbert.rank_documents(\"machine learning\", test_docs)\n",
    "print(\"== Hilbert 2: pointwise ==\")\n",
    "print(rank_results, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 26.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Hilbert 3: listwise ==\n",
      "[(np.int64(0), np.float32(0.35199177)), (np.int64(2), np.float32(0.32481337)), (np.int64(1), np.float32(0.32319486))] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SRSWTIHilbertSearch with listwise approach\n",
    "# (This considers relationships between documents in the ranking process)\n",
    "hilbert_listwise = SRSWTIHilbertSearch(approach='listwise')\n",
    "\n",
    "# Train the model using the same training data as the pointwise approach\n",
    "# The listwise approach optimizes for the entire ranked list rather than individual document scores\n",
    "hilbert_listwise.train(train_queries, train_docs, train_relevances, epochs=2)\n",
    "\n",
    "# Test the trained listwise model by ranking test documents for \"finance\" query\n",
    "# This will compare how differently the pointwise and listwise approaches rank the same documents\n",
    "rank_results_listwise = hilbert_listwise.rank_documents(\"finance\", test_docs)\n",
    "print(\"== Hilbert 3: listwise ==\")\n",
    "print(rank_results_listwise, \"\\n\")\n",
    "\n",
    "# The listwise approach is particularly useful for:\n",
    "# - Optimizing the entire ranking order rather than individual relevance scores\n",
    "# - Capturing interdependencies between documents in search results\n",
    "# - Potentially providing more coherent result sets for complex queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------- RAG Demos ---------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_demo_a(user_query, docs=SAMPLE_DOCS):\n",
    "    \"\"\"\n",
    "    Demonstrates RAG (Retrieval-Augmented Generation) using pointwise approach.\n",
    "    \n",
    "    This function ranks documents against the user query using the pointwise Hilbert model,\n",
    "    retrieves the top document, and generates an answer using an LLM.\n",
    "    \n",
    "    Args:\n",
    "        user_query (str): The query from the user\n",
    "        docs (list): List of documents to search through, defaults to SAMPLE_DOCS\n",
    "        \n",
    "    Returns:\n",
    "        None: Prints the ranked documents and LLM response\n",
    "    \"\"\"\n",
    "    ranked = hilbert.rank_documents(user_query, docs)\n",
    "    print(ranked)\n",
    "    if ranked:\n",
    "        sorted_docs = sorted(ranked, key=lambda x: x[1], reverse=True)\n",
    "        top_doc = docs[sorted_docs[0][0]]\n",
    "    else:\n",
    "        top_doc = \"No doc\"\n",
    "    prompt = f\"User query: {user_query}\\nTop doc: {top_doc}\\nAnswer the query.\"\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem11 RAG Demo A] LLM:\\n\", resp, \"\\n\")\n",
    "\n",
    "def rag_demo_b(user_query, docs=SAMPLE_DOCS):\n",
    "    \"\"\"\n",
    "    Demonstrates RAG (Retrieval-Augmented Generation) using listwise approach.\n",
    "    \n",
    "    This function ranks documents against the user query using the listwise Hilbert model,\n",
    "    retrieves the top document, and generates an answer using an LLM.\n",
    "    \n",
    "    Args:\n",
    "        user_query (str): The query from the user\n",
    "        docs (list): List of documents to search through, defaults to SAMPLE_DOCS\n",
    "        \n",
    "    Returns:\n",
    "        None: Prints the LLM response with the top document retrieval\n",
    "    \"\"\"\n",
    "    # Use listwise\n",
    "    ranked = hilbert_listwise.rank_documents(user_query, docs)\n",
    "    if ranked:\n",
    "        sorted_docs = sorted(ranked, key=lambda x: x[1], reverse=True)\n",
    "        top_doc = docs[sorted_docs[0][0]]\n",
    "    else:\n",
    "        top_doc = \"No doc\"\n",
    "    prompt = f\"User query: {user_query}\\nTop doc (listwise): {top_doc}\\nAnswer the query.\"\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem11 RAG Demo B] LLM:\\n\", resp, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(np.int64(0), np.float32(0.47484967)), (np.int64(2), np.float32(0.46288988)), (np.int64(1), np.float32(0.46054238))]\n",
      "[Theorem11 RAG Demo A] LLM:\n",
      " [Groq LLM] Machine learning is a subset of artificial intelligence that involves the use of algorithms and statistical models to enable machines to perform a specific task without using explicit instructions. One of the key concepts in machine learning is neural networks, which are computational models inspired by the human brain's architecture.\n",
      "\n",
      "Neural networks consist of interconnected nodes (neurons) organized in layers, including input, hidden, and output layers. The structure of these networks involves neurons receiving inputs, applying weights, summing them, and passing through activation functions. The learning process in neural networks occurs through the adjustment of weights during training processes like backpropagation.\n",
      "\n",
      "There are various types of neural networks, including feedforward neural networks, convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformers. These networks have numerous applications, such as image and speech recognition, natural language processing, game playing, decision making, and medical diagnosis.\n",
      "\n",
      "However, machine learning, particularly neural networks, also poses some challenges, including overfitting, computational intensity, and interpretability. Despite these challenges, neural networks remain a crucial component of machine learning, driving innovations across various fields and enabling machines to learn from data and improve their performance over time. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_a(\"Explain machine learning\", SAMPLE_DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 23.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem11 RAG Demo B] LLM:\n",
      " [Groq LLM] The provided information about neural networks is related to the topic of generative AI, as neural networks are a fundamental component of many generative AI models. However, it doesn't explicitly define what generative AI is.\n",
      "\n",
      "To answer the query: Generative AI refers to a type of artificial intelligence that uses neural networks and other machine learning algorithms to generate new, synthetic data that is similar to existing data. This can include images, videos, music, text, and other forms of data. Generative AI models, such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), use neural networks to learn patterns and structures in data and then generate new data that is consistent with those patterns.\n",
      "\n",
      "In the context of the provided information, generative AI can be seen as an application of neural networks, particularly those that involve complex architectures like CNNs, RNNs, and Transformers. However, a more detailed explanation of generative AI would require additional information beyond what is provided in the text. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_b(\"What is generative AI?\", SAMPLE_DOCS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
