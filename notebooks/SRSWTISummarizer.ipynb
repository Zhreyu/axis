{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# SRSWTISummarizer\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhreyas/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-10 20:44:47.583231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741619687.603537 1105640 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741619687.609297 1105640 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 20:44:47.630391: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:datasets:PyTorch version 2.5.0 available.\n",
      "INFO:datasets:TensorFlow version 2.18.0 available.\n",
      "INFO:datasets:JAX version 0.5.2 available.\n",
      "INFO:SRSWTI:SRSWTI Text Analysis Engine initialized successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------- Imports ------------------------------\n",
    "from srswti_axis import SRSWTISummarizer\n",
    "from utils import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------- Basic Demos ------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the summarizer\n",
    "summarizer = SRSWTISummarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SRSWTI INFO] 2025-03-10 20:53:00 - Starting single text summarization with SRSWTI-LW1\n",
      "[SRSWTI INFO] 2025-03-10 20:53:00 - Initializing SRSWTI-LW1 summarization engine on device 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Your max_length is set to 60, but your input_length is only 42. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SRSWTI INFO] 2025-03-10 20:57:29 - Engine SRSWTI-LW1 initialized successfully\n",
      "[SRSWTI METRICS] Operation: Single text summarization - Duration: 270.22 seconds\n",
      "== Summarization 1 ==\n",
      "deep neural networks have achieved state-of-the-art performance in multiple tasks . they often require large datasets and extensive computation . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a sample text about deep neural networks for summarization\n",
    "long_text_1 = \"\"\"\n",
    "Deep neural networks have achieved state-of-the-art performance in multiple tasks, \n",
    "but they often require large datasets and extensive computation. Researchers \n",
    "are investigating more efficient architectures and training methodologies.\n",
    "\"\"\"\n",
    "\n",
    "# Use the previously initialized SRSWTISummarizer to summarize the text\n",
    "# Parameters:\n",
    "# - model_key=\"SRSWTI-LW1\": Specifies which model variant to use for summarization\n",
    "# - min_length=20: Sets a minimum length constraint for the generated summary\n",
    "# - max_length=60: Sets a maximum length constraint for the generated summary\n",
    "summary_1 = summarizer.summarize_text(long_text_1, model_key=\"SRSWTI-LW1\", min_length=20, max_length=60)\n",
    "\n",
    "# Print a header for this summarization example\n",
    "print(\"== Summarization 1 ==\")\n",
    "# Print the generated summary followed by a blank line\n",
    "print(summary_1, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 50, but your input_length is only 12. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SRSWTI INFO] 2025-03-10 20:57:30 - Starting batch summarization with SRSWTI-LW1\n",
      "[SRSWTI METRICS] Operation: Batch summarization - Duration: 0.67 seconds\n",
      "== Summarization 2 ==\n",
      "[\"paragraph about climate change impacts on agriculture . ed militancy: i'm not a big fan of climate change, but i think it's a good idea .\", 'a paragraph about carbon emissions and policy changes . another paragraph about policy changes and carbon emissions . a second paragraph about . carbon emissions, policy changes...'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_texts_2 = [\n",
    "    \"Paragraph about climate change impacts on agriculture...\",\n",
    "    \"Another paragraph about carbon emissions and policy changes...\"\n",
    "]\n",
    "summary_2 = summarizer.summarize_batch(batch_texts_2, model_key=\"SRSWTI-LW1\", max_length=50)\n",
    "print(\"== Summarization 2 ==\")\n",
    "print(summary_2, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------  RAG Demos ---------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_demo_a(docs=SAMPLE_DOCS):\n",
    "    \"\"\"\n",
    "    Demonstrates a simple RAG (Retrieval-Augmented Generation) workflow \n",
    "    by summarizing multiple documents and generating an overall summary using LLM.\n",
    "    \n",
    "    Args:\n",
    "        docs (list): List of document texts to summarize. Defaults to SAMPLE_DOCS.\n",
    "    \n",
    "    Returns:\n",
    "        None: Prints the LLM-generated overall summary to console.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        print(\"[Theorem14 RAG Demo A] No docs.\")\n",
    "        return\n",
    "    sums = summarizer.summarize_batch(docs, model_key=\"SRSWTI-LW1\", max_length=40)\n",
    "    combined = \"\\n\".join(sums)\n",
    "    prompt = f\"Summaries:\\n{combined}\\nGive an overall summary.\"\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem14 RAG Demo A] LLM:\\n\", resp, \"\\n\")\n",
    "\n",
    "def rag_demo_b(user_query, docs=SAMPLE_DOCS):\n",
    "    \"\"\"\n",
    "    Demonstrates a query-focused RAG workflow by summarizing a randomly selected document\n",
    "    and using it to answer the user's specific query with an LLM.\n",
    "    \n",
    "    Args:\n",
    "        user_query (str): The user's question or request to be answered\n",
    "        docs (list): Pool of document texts to select from. Defaults to SAMPLE_DOCS.\n",
    "    \n",
    "    Returns:\n",
    "        None: Prints the LLM-generated response to the user query based on document content.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        print(\"[Theorem14 RAG Demo B] No docs.\")\n",
    "        return\n",
    "    doc = random.choice(docs)\n",
    "    summ = summarizer.summarize_text(doc, model_key=\"SRSWTI-LW1\", max_length=40)\n",
    "    prompt = (\n",
    "        f\"User query: {user_query}\\nDoc summary:\\n{summ}\\n\"\n",
    "        \"Answer the user's query based on this summary.\"\n",
    "    )\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem14 RAG Demo B] LLM:\\n\", resp, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SRSWTI INFO] 2025-03-10 20:58:01 - Starting batch summarization with SRSWTI-LW1\n",
      "[SRSWTI METRICS] Operation: Batch summarization - Duration: 0.57 seconds\n",
      "[Theorem14 RAG Demo A] LLM:\n",
      " [Groq LLM] Here's a summary of the given topics:\n",
      "\n",
      "Recent advancements in technology have led to the development of innovative computational models and systems. Neural networks, inspired by the human brain, are composed of interconnected nodes that process and transmit information. Additionally, Generative AI is being used to create unique digital assets, such as NFTs, which can be verified through smart contracts. Meanwhile, quantum computers, which utilize qubits that can exist in multiple states simultaneously, have the potential to perform complex calculations at an exponentially faster rate than classical computers. These breakthroughs are transforming various fields, from artificial intelligence to digital ownership and computing. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_a(SAMPLE_DOCS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SRSWTI INFO] 2025-03-10 20:58:35 - Starting single text summarization with SRSWTI-LW1\n",
      "[SRSWTI METRICS] Operation: Single text summarization - Duration: 0.45 seconds\n",
      "[Theorem14 RAG Demo B] LLM:\n",
      " [Groq LLM] GEN AI in Blockchain refers to the integration of Generative AI (GEN AI) with blockchain technology. This integration enables the creation of unique digital assets, such as AI-generated art, that can be minted as Non-Fungible Tokens (NFTs). \n",
      "\n",
      "The use of blockchain smart contracts allows for the verification of the authenticity and provenance of these AI-generated digital assets. This means that the ownership, origin, and history of the digital assets can be securely tracked and validated on the blockchain, ensuring their legitimacy and value.\n",
      "\n",
      "In essence, GEN AI in blockchain combines the creative potential of generative AI with the secure and decentralized nature of blockchain, opening up new possibilities for digital art, collectibles, and other unique digital assets. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_b(\"Explain GEN AI in Blockchain\", SAMPLE_DOCS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
