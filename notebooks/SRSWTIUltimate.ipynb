{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# SRSWTIUltimate\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhreyas/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-10 21:20:56.340465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741621856.360049 1146801 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741621856.365288 1146801 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 21:20:56.385723: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:datasets:PyTorch version 2.5.0 available.\n",
      "INFO:datasets:TensorFlow version 2.18.0 available.\n",
      "INFO:datasets:JAX version 0.5.2 available.\n",
      "INFO:SRSWTI:SRSWTI Text Analysis Engine initialized successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------  Imports ------------------------------\n",
    "from srswti_axis import SRSWTIUltimate\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------  Basic 3 Demos ------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "ultimate_engine = SRSWTIUltimate()\n",
    "ult_docs = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"GPU-based training accelerates deep learning significantly.\",\n",
    "    \"Universal Language Models can handle multiple languages seamlessly.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Ultimate 1 ==\n",
      "[{'document': 'GPU-based training accelerates deep learning significantly.', 'score': np.float64(0.5386987024735129), 'pagerank': 0.3411716203526378, 'cluster': 0}] \n",
      "\n",
      "Doc: GPU-based training accelerates deep learning significantly. | Cluster: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Index the documents in our ultimate search engine\n",
    "ultimate_engine.index_documents(ult_docs)\n",
    "\n",
    "# Search for \"deep learning GPU\" and get top 1 result using combined ranking method\n",
    "ult_res_1 = ultimate_engine.search(\"deep learning GPU\", n_results=1, ranking_method='combined')\n",
    "\n",
    "# Print the raw search results\n",
    "print(\"== Ultimate 1 ==\")\n",
    "print(ult_res_1, \"\\n\")\n",
    "\n",
    "# Loop through each search result and display in a readable format\n",
    "for r in ult_res_1:\n",
    "    # Print document text and its assigned cluster\n",
    "    print(\"Doc:\", r[\"document\"], \"| Cluster:\", r[\"cluster\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------RAG Demos ---------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rag_demo_a(user_query, docs=SAMPLE_DOCS):\n",
    "    ultimate_engine.index_documents(docs)\n",
    "    results = ultimate_engine.search(user_query, n_results=2, ranking_method='combined')\n",
    "    if results:\n",
    "        top_doc = results[0][\"document\"]\n",
    "    else:\n",
    "        top_doc = \"No doc\"\n",
    "    prompt = (\n",
    "        f\"User query: {user_query}\\nTop doc:\\n{top_doc}\\n\"\n",
    "        \"Please provide relevant info. using only top doc.\"\n",
    "    )\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem16 RAG Demo A] LLM:\\n\", resp, \"\\n\")\n",
    "\n",
    "def rag_demo_b(docs=SAMPLE_DOCS):\n",
    "    ultimate_engine.index_documents(docs)\n",
    "    results = ultimate_engine.search(\"quantum computing\", n_results=3, ranking_method='combined')\n",
    "    cluster_info = [(r[\"document\"], r[\"cluster\"]) for r in results]\n",
    "    prompt = (\n",
    "        f\"Docs + cluster info:\\n{cluster_info}\\nExplain how they are clustered. from the info provided.\"\n",
    "    )\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem16 RAG Demo B] LLM:\\n\", resp, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem16 RAG Demo A] LLM:\n",
      " [Groq LLM] Based on the provided overview of Neural Networks, here's a comparison with classical ML approaches:\n",
      "\n",
      "**Key differences:**\n",
      "\n",
      "1. **Inspiration and Structure**: Neural networks are inspired by the human brain's architecture, consisting of interconnected nodes (neurons) organized in layers. In contrast, classical ML approaches are often based on statistical models and don't mimic the brain's structure.\n",
      "2. **Learning Process**: Neural networks learn by adjusting weights through training processes like backpropagation, whereas classical ML approaches typically rely on other optimization techniques.\n",
      "3. **Handling Complex Data**: Neural networks, especially types like CNNs, RNNs, and Transformers, are specialized to handle complex data such as images, sequential data, and natural language. Classical ML approaches might struggle with these types of data.\n",
      "\n",
      "**Unique aspects of Neural Networks:**\n",
      "\n",
      "1. **Activation Functions**: Neural networks use activation functions like ReLU, sigmoid, or tanh to determine neuron output, which is not a characteristic of classical ML approaches.\n",
      "2. **Types of Neural Networks**: The existence of various neural network types (Feedforward, CNNs, RNNs, Transformers) allows for a wide range of applications, which might not be possible with classical ML approaches.\n",
      "\n",
      "**Common challenges:**\n",
      "\n",
      "1. **Overfitting**: Both neural networks and classical ML approaches can suffer from overfitting, although neural networks are more prone to it due to their complexity.\n",
      "2. **Computational Intensity**: Neural networks are often more computationally intensive than classical ML approaches, especially during training.\n",
      "\n",
      "Overall, neural networks offer a unique approach to machine learning, inspired by the human brain's architecture, and are particularly well-suited for handling complex data. However, they also come with specific challenges that need to be addressed. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_a(\"Explain neural networks vs classical ML approaches\", SAMPLE_DOCS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem16 RAG Demo B] LLM:\n",
      " [Groq LLM] The documents are clustered into three groups, as indicated by the identical cluster label (0) for each document. This suggests that the clustering algorithm has grouped all the documents into a single cluster.\n",
      "\n",
      "In other words, the documents are not separated into distinct clusters based on their content, but rather are treated as a single group. This could be due to various reasons such as:\n",
      "\n",
      "* The clustering algorithm used is not suitable for the specific characteristics of the documents.\n",
      "* The documents are not diverse enough to be separated into distinct clusters.\n",
      "* The number of clusters specified (which is not provided in the given information) is set to 1, resulting in all documents being grouped together.\n",
      "\n",
      "The topics of the documents appear to be related to emerging technologies, including quantum computing, generative AI, blockchain, and neural networks. They discuss the principles, applications, and challenges of these technologies, which may suggest that they could be clustered into separate groups based on their topics. However, based on the provided cluster labels, the documents are currently grouped into a single cluster. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_b(SAMPLE_DOCS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
