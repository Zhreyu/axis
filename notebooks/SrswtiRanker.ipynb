{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# SrswtiRanker\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhreyas/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-10 15:15:09.699301: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741599909.718948  944293 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741599909.724249  944293 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 15:15:09.745731: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:datasets:PyTorch version 2.5.0 available.\n",
      "INFO:datasets:TensorFlow version 2.18.0 available.\n",
      "INFO:datasets:JAX version 0.5.2 available.\n",
      "INFO:SRSWTI:SRSWTI Text Analysis Engine initialized successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------  Imports -------------------------------\n",
    "from srswti_axis import SrswtiRanker\n",
    "from utils import call_groq_llm, SAMPLE_DOCS\n",
    "# ---------------------------  Basic 3 Demos -------------------------\n",
    "basic_ranker = SrswtiRanker()\n",
    "ranker_docs = [\n",
    "    \"PyTorch is a deep learning framework\",\n",
    "    \"TensorFlow is for large-scale machine learning\",\n",
    "    \"Keras builds on top of TensorFlow\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Ranker 1 ==\n",
      "[('TensorFlow is for large-scale machine learning', 0.47151875495910645), ('PyTorch is a deep learning framework', 0.28279903531074524), ('Keras builds on top of TensorFlow', 0.1134694516658783)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the basic_ranker to rank the documents based on their relevance to the query\n",
    "# The rank_documents method returns documents sorted by relevance score (highest first)\n",
    "ranking_res_1 = basic_ranker.rank_documents(\"machine learning frameworks\", ranker_docs)\n",
    "print(\"== Ranker 1 ==\")\n",
    "print(ranking_res_1, \"\\n\")  # Print the ranked documents with newline for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Ranker 2 ==\n",
      "['TensorFlow is for large-scale machine learning', 'Keras builds on top of TensorFlow'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the filter_documents method to select only documents that meet a threshold relevance score\n",
    "\n",
    "\n",
    "filtered_docs_2 = basic_ranker.filter_documents(\"TensorFlow library\", ranker_docs, threshold=0.6)\n",
    "print(\"== Ranker 2 ==\")\n",
    "print(filtered_docs_2, \"\\n\")  # Prints only documents with relevance score >= 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Ranker 3 ==\n",
      "['PyTorch is a deep learning framework', 'TensorFlow is for large-scale machine learning'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_k_3 = basic_ranker.get_top_k(\"deep learning\", ranker_docs, k=2)\n",
    "print(\"== Ranker 3 ==\")\n",
    "print(top_k_3, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------  RAG Demos ----------------------\n",
    "def rag_demo_a(user_query, docs=SAMPLE_DOCS):\n",
    "    \"\"\"\n",
    "    Demonstrates a simple RAG system that selects the top-ranked document \n",
    "    and passes it to the LLM to generate a response.\n",
    "    \n",
    "    Args:\n",
    "        user_query (str): The user's query or question\n",
    "        docs (list): List of documents to search through (defaults to SAMPLE_DOCS)\n",
    "        \n",
    "    Returns:\n",
    "        None: Prints LLM response to console\n",
    "    \"\"\"\n",
    "    ranked = basic_ranker.rank_documents(user_query, docs)\n",
    "    if ranked:\n",
    "        top_doc = ranked[0]\n",
    "    else:\n",
    "        top_doc = \"No doc\"\n",
    "    prompt = f\"User query: {user_query}\\nTop doc: {top_doc}\\nRespond to the query.\"\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem9 RAG Demo A] LLM:\\n\", resp, \"\\n\")\n",
    "\n",
    "def rag_demo_b(user_query, docs=SAMPLE_DOCS):\n",
    "    \"\"\"\n",
    "    Demonstrates a more advanced RAG system that filters documents based on\n",
    "    relevance threshold, combines all relevant documents, and asks the LLM\n",
    "    to summarize the information.\n",
    "    \n",
    "    Args:\n",
    "        user_query (str): The user's query or question\n",
    "        docs (list): List of documents to search through (defaults to SAMPLE_DOCS)\n",
    "        \n",
    "    Returns:\n",
    "        None: Prints LLM response to console\n",
    "    \"\"\"\n",
    "    relevant = basic_ranker.filter_documents(user_query, docs, threshold=0.2)\n",
    "    combined = \"\\n\".join(relevant) if relevant else \"No relevant docs.\"\n",
    "    prompt = f\"User query: {user_query}\\nRelevant docs:\\n{combined}\\nSummarize.\"\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem9 RAG Demo B] LLM:\\n\", resp, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem9 RAG Demo A] LLM:\n",
      " [Groq LLM] When comparing classical machine learning (ML) to neural networks, there are significant differences in their approach, capabilities, and applications. \n",
      "\n",
      "Classical ML typically involves traditional algorithms like decision trees, linear regression, and support vector machines. These methods are often used for simpler problems and are more interpretable, meaning it's easier to understand how they arrive at their predictions. However, they can be limited in their ability to handle complex, high-dimensional data.\n",
      "\n",
      "On the other hand, neural networks are computational models inspired by the human brain's architecture. They consist of interconnected nodes (neurons) organized in layers: input, hidden, and output layers. Neural networks are capable of learning complex patterns in data, especially in cases where the data is high-dimensional, like images or speech. They have been particularly successful in areas such as image and speech recognition, natural language processing, and game playing.\n",
      "\n",
      "There are several types of neural networks, including feedforward neural networks, convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformers, each specialized for different tasks. For example, CNNs are designed for image processing and have been instrumental in self-driving cars and facial recognition systems. RNNs, with their ability to handle sequential data, are often used in speech recognition and natural language processing tasks.\n",
      "\n",
      "Neural networks learn by adjusting the weights between neurons through training processes like backpropagation, allowing them to improve their predictions over time. The choice of activation functions, such as ReLU, sigmoid, or tanh, plays a crucial role in determining the output of each neuron.\n",
      "\n",
      "Despite their powerful capabilities, neural networks also come with challenges. Overfitting, where the model becomes too specialized to the training data and fails to generalize well to new, unseen data, is a common issue. Additionally, neural networks can be computationally intensive, requiring significant resources to train, especially on large datasets. Furthermore, their complexity can make them less interpretable than classical ML models, making it harder to understand why a particular decision was made.\n",
      "\n",
      "In summary, while classical ML methods are straightforward and interpretable, they often struggle with complex data. Neural networks, on the other hand, excel with high-dimensional, complex data but come with their own set of challenges, including overfitting, computational intensity, and interpretability issues. The choice between classical ML and neural networks depends on the nature of the problem, the complexity of the data, and the specific requirements of the application. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_a(\"Tell me about classical ML vs neural networks\", SAMPLE_DOCS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem9 RAG Demo B] LLM:\n",
      " [Groq LLM] Quantum computing has the potential to significantly impact cryptography, as it can perform certain calculations exponentially faster than classical computers. This could break widely-used encryption schemes that rely on factoring large prime numbers, using algorithms like Shor's. As a result, post-quantum cryptography methods are being developed to withstand quantum attacks. However, practical quantum computers capable of breaking current encryption are still years away due to challenges like qubit stability, error correction, and scaling issues. Companies are working to build more powerful quantum processors, but building fault-tolerant, general-purpose quantum computers remains an ongoing challenge. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_b(\"quantum computing for cryptography\", SAMPLE_DOCS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
