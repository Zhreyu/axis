{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# SrswtiDeduplicator\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhreyas/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-10 15:12:22.684475: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741599742.703847  941064 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741599742.709013  941064 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 15:12:22.729694: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:datasets:PyTorch version 2.5.0 available.\n",
      "INFO:datasets:TensorFlow version 2.18.0 available.\n",
      "INFO:datasets:JAX version 0.5.2 available.\n",
      "INFO:SRSWTI:SRSWTI Text Analysis Engine initialized successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------- Imports -------------------------------\n",
    "from srswti_axis import SrswtiDeduplicator\n",
    "from utils import call_groq_llm,SAMPLE_DOCS\n",
    "# --------------------------- Basic 3 Demos -------------------------\n",
    "\n",
    "# Initialize the deduplicator\n",
    "deduper = SrswtiDeduplicator()\n",
    "\n",
    "# Sample Docs\n",
    "docs_dedupe = [\n",
    "    \"This is a unique sentence about traveling to Mars.\",\n",
    "    \"This is a unique sentence about traveling to Mars.\",\n",
    "    \"Different content about traveling to Jupiter.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Dedupe 1 ==\n",
      "['This is a unique sentence about traveling to Mars.', 'Different content about traveling to Jupiter.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deduplicate the sample documents with a threshold of 0.8\n",
    "# This removes similar documents based on semantic similarity\n",
    "unique_docs_1 = deduper.deduplicate(docs_dedupe, threshold=0.8)\n",
    "\n",
    "# Print the results of the first deduplication example\n",
    "print(\"== Dedupe 1 ==\")\n",
    "print(unique_docs_1, \"\\n\")  # \\n adds a blank line after the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Dedupe 2 (indices) ==\n",
      "1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Second deduplication example\n",
    "unique_docs_2 = deduper.deduplicate(docs_dedupe, threshold=0.8, return_indices=True)\n",
    "print(\"== Dedupe 2 (indices) ==\")\n",
    "print(unique_docs_2[0], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# ------------------- - RAG Demos ----------------------\n",
    "def rag_demo_a(docs=SAMPLE_DOCS):\n",
    "    \"\"\"\n",
    "    Demonstrates a basic RAG workflow by deduplicating documents and asking the LLM to summarize them.\n",
    "    \n",
    "    This function:\n",
    "    1. Deduplicates the input documents with a 0.9 similarity threshold\n",
    "    2. Creates a prompt requesting a summary of the unique documents\n",
    "    3. Calls a Groq LLM to generate the summary\n",
    "    4. Prints the LLM's response\n",
    "    \n",
    "    Args:\n",
    "        docs (list): List of text documents to process (defaults to SAMPLE_DOCS)\n",
    "    \"\"\"\n",
    "    unique = deduper.deduplicate(docs, threshold=0.9)\n",
    "    prompt = f\"Unique docs:\\n{unique}\\nSummarize them briefly.\"\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem8 RAG Demo A] LLM:\\n\", resp, \"\\n\")\n",
    "\n",
    "def rag_demo_b(user_query, docs=SAMPLE_DOCS):\n",
    "    \"\"\"\n",
    "    Demonstrates a query-based RAG workflow with document deduplication.\n",
    "    \n",
    "    This function:\n",
    "    1. Deduplicates the input documents with a 0.9 similarity threshold\n",
    "    2. Randomly selects one unique document as context\n",
    "    3. Creates a prompt with the user's query and the selected document\n",
    "    4. Calls a Groq LLM to generate a response based on the context\n",
    "    5. Prints the LLM's response\n",
    "    \n",
    "    Args:\n",
    "        user_query (str): The user's question or request\n",
    "        docs (list): List of text documents to process (defaults to SAMPLE_DOCS)\n",
    "    \"\"\"\n",
    "    unique = deduper.deduplicate(docs, threshold=0.9)\n",
    "    chosen = random.choice(unique) if unique else \"No doc found.\"\n",
    "    prompt = (\n",
    "        f\"User query: {user_query}\\nChosen doc:\\n{chosen}\\n\"\n",
    "        \"Respond accordingly.\"\n",
    "    )\n",
    "    resp = call_groq_llm(prompt)\n",
    "    print(\"[Theorem8 RAG Demo B] LLM:\\n\", resp, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem8 RAG Demo A] LLM:\n",
      " [Groq LLM] Here's a brief summary of the unique documents:\n",
      "\n",
      "1. **Neural Networks**: An overview of neural networks, including their structure, learning process, types (e.g., CNNs, RNNs), and applications (e.g., image recognition, natural language processing).\n",
      "2. **Generative AI and Blockchain Integration**: Exploring the intersection of generative AI and blockchain technology, including NFT creation, decentralized AI training, and on-chain AI models, as well as challenges and considerations.\n",
      "3. **Quantum Computing**: Introducing quantum computing, its principles, and potential impact on fields like cryptography, drug discovery, and artificial intelligence, while highlighting current challenges and the ongoing development of more powerful quantum processors. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_a(SAMPLE_DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Theorem8 RAG Demo B] LLM:\n",
      " [Groq LLM] The provided document does not discuss the impact of quantum computing on cryptography. It focuses on the integration of generative AI and blockchain technology, covering topics such as NFT creation, decentralized AI training, on-chain AI models, governance, and data marketplaces. If you're looking for information on how quantum computing affects cryptography, I'd be happy to provide a general overview.\n",
      "\n",
      "Quantum computing has the potential to significantly impact cryptography, as it can potentially break certain types of classical encryption algorithms. Quantum computers can process vast amounts of information in parallel, making them much faster than classical computers for certain types of calculations. This means that quantum computers could potentially factor large numbers exponentially faster than classical computers, which would break many encryption algorithms currently in use, such as RSA.\n",
      "\n",
      "However, quantum computing also has the potential to enable new, quantum-resistant encryption methods, such as quantum key distribution and lattice-based cryptography. These methods are designed to be secure against quantum computers and could potentially replace classical encryption algorithms in the future.\n",
      "\n",
      "If you have any further questions or would like more information on this topic, feel free to ask! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_demo_b(\"How can quantum computing affect cryptography?\", SAMPLE_DOCS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
